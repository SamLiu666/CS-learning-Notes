{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果需要训练的数据大小不大，例如不到1G，那么可以直接全部读入内存中进行训练，这样一般效率最高。\n",
    "\n",
    "但如果需要训练的数据很大，例如超过10G，无法一次载入内存，那么通常需要在训练的过程中分批逐渐读入。\n",
    "\n",
    "使用 tf.data API 可以构建数据输入管道，轻松处理大量的数据，不同的数据格式，以及不同的数据转换。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 从numpy array构建数据管道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\envs\\tensorflow2.0\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda\\envs\\tensorflow2.0\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda\\envs\\tensorflow2.0\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda\\envs\\tensorflow2.0\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda\\envs\\tensorflow2.0\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda\\envs\\tensorflow2.0\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "D:\\Anaconda\\envs\\tensorflow2.0\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\Anaconda\\envs\\tensorflow2.0\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\Anaconda\\envs\\tensorflow2.0\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\Anaconda\\envs\\tensorflow2.0\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\Anaconda\\envs\\tensorflow2.0\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\Anaconda\\envs\\tensorflow2.0\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用iris 数据集\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([5.1 3.5 1.4 0.2], shape=(4,), dtype=float64) \n",
      " tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor([4.9 3.  1.4 0.2], shape=(4,), dtype=float64) \n",
      " tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor([4.7 3.2 1.3 0.2], shape=(4,), dtype=float64) \n",
      " tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor([4.6 3.1 1.5 0.2], shape=(4,), dtype=float64) \n",
      " tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor([5.  3.6 1.4 0.2], shape=(4,), dtype=float64) \n",
      " tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "ds1 = tf.data.Dataset.from_tensor_slices((iris[\"data\"], iris[\"target\"]))\n",
    "for features, label in ds1.take(5):\n",
    "#     print(features)\n",
    "#     print(label, \"label\")\n",
    "    print(features,'\\n',label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2从 Pandas DataFrame构建数据管道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sepal length (cm)': <tf.Tensor: id=46, shape=(), dtype=float32, numpy=5.1>, 'sepal width (cm)': <tf.Tensor: id=47, shape=(), dtype=float32, numpy=3.5>, 'petal length (cm)': <tf.Tensor: id=44, shape=(), dtype=float32, numpy=1.4>, 'petal width (cm)': <tf.Tensor: id=45, shape=(), dtype=float32, numpy=0.2>} \n",
      " tf.Tensor(0, shape=(), dtype=int32)\n",
      "{'sepal length (cm)': <tf.Tensor: id=56, shape=(), dtype=float32, numpy=4.9>, 'sepal width (cm)': <tf.Tensor: id=57, shape=(), dtype=float32, numpy=3.0>, 'petal length (cm)': <tf.Tensor: id=54, shape=(), dtype=float32, numpy=1.4>, 'petal width (cm)': <tf.Tensor: id=55, shape=(), dtype=float32, numpy=0.2>} \n",
      " tf.Tensor(0, shape=(), dtype=int32)\n",
      "{'sepal length (cm)': <tf.Tensor: id=66, shape=(), dtype=float32, numpy=4.7>, 'sepal width (cm)': <tf.Tensor: id=67, shape=(), dtype=float32, numpy=3.2>, 'petal length (cm)': <tf.Tensor: id=64, shape=(), dtype=float32, numpy=1.3>, 'petal width (cm)': <tf.Tensor: id=65, shape=(), dtype=float32, numpy=0.2>} \n",
      " tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "iris = datasets.load_iris()\n",
    "dfiris = pd.DataFrame(iris[\"data\"],columns = iris.feature_names)\n",
    "ds2 = tf.data.Dataset.from_tensor_slices((dfiris.to_dict(\"list\"),iris[\"target\"]))\n",
    "\n",
    "for features,label in ds2.take(3):\n",
    "    print(features,'\\n',label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 从Python generator构建数据管道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 定义一个从文件中读取图片的generator\n",
    "# image_generator = ImageDataGenerator(rescale=1.0/255).flow_from_directory(\n",
    "#                     \"./data/cifar2/test/\",\n",
    "#                     target_size=(32, 32),\n",
    "#                     batch_size=20,\n",
    "#                     class_mode='binary')\n",
    "\n",
    "# classdict = image_generator.class_indices\n",
    "# print(classdict)\n",
    "\n",
    "# def generator():\n",
    "#     for features,label in image_generator:\n",
    "#         yield (features,label)\n",
    "\n",
    "# ds3 = tf.data.Dataset.from_generator(generator,output_types=(tf.float32,tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'svg'\n",
    "# plt.figure(figsize=(6,6)) \n",
    "# for i,(img,label) in enumerate(ds3.unbatch().take(9)):\n",
    "#     ax=plt.subplot(3,3,i+1)\n",
    "#     ax.imshow(img.numpy())\n",
    "#     ax.set_title(\"label = %d\"%label)\n",
    "#     ax.set_xticks([])\n",
    "#     ax.set_yticks([]) \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 应用数据转换\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MapDataset shapes: (None,), types: tf.string> \n",
      " <TensorSliceDataset shapes: (), types: tf.string>\n",
      "tf.Tensor([b'H,' b'h'], shape=(2,), dtype=string)\n",
      "tf.Tensor([b'S,' b's'], shape=(2,), dtype=string)\n",
      "tf.Tensor([b'Z,' b'z'], shape=(2,), dtype=string)\n",
      "tf.Tensor([b'H' b'h'], shape=(2,), dtype=string)\n",
      "tf.Tensor([b'S' b's'], shape=(2,), dtype=string)\n",
      "tf.Tensor([b'Z' b'z'], shape=(2,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# map 将转换函数映射到数据集的每一个元素\n",
    "ds = tf.data.Dataset.from_tensor_slices([\"H, h\", \"S, s\", \"Z, z\"])\n",
    "ds_map = ds.map(lambda x:tf.strings.split(x, \" \"))\n",
    "ds_map1 = ds.map(lambda x:tf.strings.split(x, \", \"))\n",
    "print(ds_map,'\\n', ds)\n",
    "for x in ds_map:\n",
    "    print(x)\n",
    "for y in ds_map1:\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'hello', shape=(), dtype=string)\n",
      "tf.Tensor(b'world', shape=(), dtype=string)\n",
      "tf.Tensor(b'hello', shape=(), dtype=string)\n",
      "tf.Tensor(b'China', shape=(), dtype=string)\n",
      "tf.Tensor(b'hello', shape=(), dtype=string)\n",
      "tf.Tensor(b'Beijing', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "#flat_map:将转换函数映射到数据集的每一个元素，并将嵌套的Dataset压平。\n",
    "\n",
    "ds = tf.data.Dataset.from_tensor_slices([\"hello world\",\"hello China\",\"hello Beijing\"])\n",
    "ds_flatmap = ds.flat_map(lambda x:tf.data.Dataset.from_tensor_slices(tf.strings.split(x,\" \")))\n",
    "for x in ds_flatmap:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'hello', shape=(), dtype=string)\n",
      "tf.Tensor(b'hello', shape=(), dtype=string)\n",
      "tf.Tensor(b'hello', shape=(), dtype=string)\n",
      "tf.Tensor(b'world', shape=(), dtype=string)\n",
      "tf.Tensor(b'China', shape=(), dtype=string)\n",
      "tf.Tensor(b'Beijing', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# interleave: 效果类似flat_map,但可以将不同来源的数据夹在一起。\n",
    "\n",
    "ds = tf.data.Dataset.from_tensor_slices([\"hello world\",\"hello China\",\"hello Beijing\"])\n",
    "ds_interleave = ds.interleave(lambda x:tf.data.Dataset.from_tensor_slices(tf.strings.split(x,\" \")))\n",
    "for x in ds_interleave:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'hello China', shape=(), dtype=string)\n",
      "tf.Tensor(b'hello Beijing', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "#filter:过滤掉某些元素。\n",
    "\n",
    "ds = tf.data.Dataset.from_tensor_slices([\"hello world\",\"hello China\",\"hello Beijing\"])\n",
    "#找出含有字母a或B的元素\n",
    "ds_filter = ds.filter(lambda x: tf.strings.regex_full_match(x, \".*[a|B].*\"))\n",
    "for x in ds_filter:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<RangeDataset shapes: (), types: tf.int64>\n",
      "0 3 6\n",
      "1 4 7\n",
      "2 5 8\n"
     ]
    }
   ],
   "source": [
    "#zip:将两个长度相同的Dataset横向铰合。\n",
    "ds1 = tf.data.Dataset.range(0,3)\n",
    "ds2 = tf.data.Dataset.range(3,6)\n",
    "ds3 = tf.data.Dataset.range(6,9)\n",
    "print(ds1)\n",
    "ds_zip = tf.data.Dataset.zip((ds1,ds2,ds3))\n",
    "for x,y,z in ds_zip:\n",
    "    print(x.numpy(),y.numpy(),z.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(3, shape=(), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "tf.Tensor(5, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "#condatenate:将两个Dataset纵向连接。\n",
    "\n",
    "ds1 = tf.data.Dataset.range(0,3)\n",
    "ds2 = tf.data.Dataset.range(3,6)\n",
    "ds_concat = tf.data.Dataset.concatenate(ds1,ds2)\n",
    "# print(tf.rank(ds_concat))\n",
    "for x in ds_concat:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1238, shape=(), dtype=float32, numpy=15.0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reduce:执行归并操作。\n",
    "\n",
    "ds = tf.data.Dataset.from_tensor_slices([1,2,3,4,5.0])\n",
    "result = ds.reduce(0.0,lambda x,y:tf.add(x,y))\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2 3], shape=(4,), dtype=int64)\n",
      "tf.Tensor([4 5 6 7], shape=(4,), dtype=int64)\n",
      "tf.Tensor([ 8  9 10 11], shape=(4,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "#batch:构建批次，每次放一个批次。比原始数据增加一个维度。 其逆操作为unbatch。 \n",
    "\n",
    "ds = tf.data.Dataset.range(12)\n",
    "ds_batch = ds.batch(4)\n",
    "for x in ds_batch:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda\\envs\\tensorflow2.0\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:505: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "tf.Tensor(\n",
      "[[1 2 0 0]\n",
      " [3 4 5 0]], shape=(2, 4), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[6 7 0 0]\n",
      " [8 0 0 0]], shape=(2, 4), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#padded_batch:构建批次，类似batch, 但可以填充到相同的形状。\n",
    "\n",
    "elements = [[1, 2],[3, 4, 5],[6, 7],[8]]\n",
    "ds = tf.data.Dataset.from_generator(lambda: iter(elements), tf.int32)\n",
    "\n",
    "ds_padded_batch = ds.padded_batch(2,padded_shapes = [4,])\n",
    "for x in ds_padded_batch:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0 1 2], shape=(3,), dtype=int64)\n",
      "tf.Tensor([1 2 3], shape=(3,), dtype=int64)\n",
      "tf.Tensor([2 3 4], shape=(3,), dtype=int64)\n",
      "tf.Tensor([3 4 5], shape=(3,), dtype=int64)\n",
      "tf.Tensor([4 5 6], shape=(3,), dtype=int64)\n",
      "tf.Tensor([5 6 7], shape=(3,), dtype=int64)\n",
      "tf.Tensor([6 7 8], shape=(3,), dtype=int64)\n",
      "tf.Tensor([7 8 9], shape=(3,), dtype=int64)\n",
      "tf.Tensor([ 8  9 10], shape=(3,), dtype=int64)\n",
      "tf.Tensor([ 9 10 11], shape=(3,), dtype=int64)\n",
      "<_VariantDataset shapes: (), types: tf.int64>\n",
      "<_VariantDataset shapes: (), types: tf.int64>\n",
      "<_VariantDataset shapes: (), types: tf.int64>\n",
      "<_VariantDataset shapes: (), types: tf.int64>\n",
      "<_VariantDataset shapes: (), types: tf.int64>\n",
      "<_VariantDataset shapes: (), types: tf.int64>\n",
      "<_VariantDataset shapes: (), types: tf.int64>\n",
      "<_VariantDataset shapes: (), types: tf.int64>\n",
      "<_VariantDataset shapes: (), types: tf.int64>\n",
      "<_VariantDataset shapes: (), types: tf.int64>\n",
      "<_VariantDataset shapes: (), types: tf.int64>\n",
      "<_VariantDataset shapes: (), types: tf.int64>\n"
     ]
    }
   ],
   "source": [
    "#window:构建滑动窗口，返回Dataset of Dataset.\n",
    "\n",
    "ds = tf.data.Dataset.range(12)\n",
    "#window返回的是Dataset of Dataset,可以用flat_map压平\n",
    "ds_window = ds.window(3, shift=1).flat_map(lambda x: x.batch(3,drop_remainder=True)) \n",
    "ds_window1 = ds.window(3, shift=1)\n",
    "for x in ds_window:\n",
    "    print(x)\n",
    "for x in ds_window1:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(3, shape=(), dtype=int64)\n",
      "tf.Tensor(5, shape=(), dtype=int64)\n",
      "tf.Tensor(7, shape=(), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(9, shape=(), dtype=int64)\n",
      "tf.Tensor(10, shape=(), dtype=int64)\n",
      "tf.Tensor(11, shape=(), dtype=int64)\n",
      "tf.Tensor(8, shape=(), dtype=int64)\n",
      "tf.Tensor(6, shape=(), dtype=int64)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "#shuffle:数据顺序洗牌。\n",
    "\n",
    "ds = tf.data.Dataset.range(12)\n",
    "ds_shuffle = ds.shuffle(buffer_size = 5)\n",
    "for x in ds_shuffle:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n",
      "tf.Tensor(0, shape=(), dtype=int64)\n",
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(2, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "#repeat:重复数据若干次，不带参数时，重复无数次。\n",
    "\n",
    "ds = tf.data.Dataset.range(3)\n",
    "ds_repeat = ds.repeat(3)\n",
    "for x in ds_repeat:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int64)\n",
      "tf.Tensor(4, shape=(), dtype=int64)\n",
      "tf.Tensor(7, shape=(), dtype=int64)\n",
      "tf.Tensor(10, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "#shard:采样，从某个位置开始隔固定距离采样一个元素。\n",
    "\n",
    "ds = tf.data.Dataset.range(12)\n",
    "ds_shard = ds.shard(3,index = 1)\n",
    "\n",
    "for x in ds_shard:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 三，提升管道性能\n",
    "训练深度学习模型常常会非常耗时。模型训练的耗时主要来自于两个部分，一部分来自数据准备，另一部分来自参数迭代,而数据准备过程的耗时则可以通过构建高效的数据管道进行提升。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#打印时间分割线\n",
    "@tf.function\n",
    "def printbar():\n",
    "    ts = tf.timestamp()\n",
    "    today_ts = ts%(24*60*60)\n",
    "\n",
    "    hour = tf.cast(today_ts//3600+8,tf.int32)%tf.constant(24)\n",
    "    minite = tf.cast((today_ts%3600)//60,tf.int32)\n",
    "    second = tf.cast(tf.floor(today_ts%60),tf.int32)\n",
    "\n",
    "    def timeformat(m):\n",
    "        if tf.strings.length(tf.strings.format(\"{}\",m))==1:\n",
    "            return(tf.strings.format(\"0{}\",m))\n",
    "        else:\n",
    "            return(tf.strings.format(\"{}\",m))\n",
    "\n",
    "    timestring = tf.strings.join([timeformat(hour),timeformat(minite),\n",
    "                timeformat(second)],separator = \":\")\n",
    "    tf.print(\"==========\"*8,end = \"\")\n",
    "    tf.print(timestring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# 数据准备和参数迭代两个过程默认情况下是串行的。\n",
    "\n",
    "# 模拟数据准备\n",
    "def generator():\n",
    "    for i in range(10):\n",
    "        #假设每次准备数据需要2s\n",
    "        time.sleep(2) \n",
    "        yield i \n",
    "ds = tf.data.Dataset.from_generator(generator,output_types = (tf.int32))\n",
    "\n",
    "# 模拟参数迭代\n",
    "def train_step():\n",
    "    #假设每一步训练需要1s\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function printbar at 0x000002CCE6307798> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function printbar at 0x000002CCE6307798>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <function printbar at 0x000002CCE6307798> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <function printbar at 0x000002CCE6307798>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "================================================================================14:29:0\n",
      "start training...\n",
      "================================================================================14:29:30\n",
      "end training...\n"
     ]
    }
   ],
   "source": [
    "# 训练过程预计耗时 10*2+10*1+ = 30s\n",
    "printbar()\n",
    "tf.print(tf.constant(\"start training...\"))\n",
    "for x in ds:\n",
    "    train_step()  \n",
    "printbar()\n",
    "tf.print(tf.constant(\"end training...\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================14:29:30\n",
      "start training with prefetch...\n",
      "================================================================================14:29:51\n",
      "end training...\n"
     ]
    }
   ],
   "source": [
    "# 使用 prefetch 方法让数据准备和参数迭代两个过程相互并行。\n",
    "\n",
    "# 训练过程预计耗时 max(10*2,10*1) = 20s\n",
    "printbar()\n",
    "tf.print(tf.constant(\"start training with prefetch...\"))\n",
    "\n",
    "# tf.data.experimental.AUTOTUNE 可以让程序自动选择合适的参数\n",
    "for x in ds.prefetch(buffer_size = tf.data.experimental.AUTOTUNE):\n",
    "    train_step()  \n",
    "\n",
    "printbar()\n",
    "tf.print(tf.constant(\"end training...\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
